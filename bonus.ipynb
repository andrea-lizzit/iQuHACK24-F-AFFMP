{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical estimate of the optimal CZ gate in hybrid encoding in the KLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target operation in the Fock basis is one that brings $|0010>|01>$ into $-|0010>|01>$, $|0001>|01>$ into $-|0001>|01>$ and acts as the identity on the rest. The operator that describes this transformation is the target $A_t$.\n",
    "\n",
    "The problem is framed as an optimization problem on the unitary matrix $\\Lambda$ which determines the transformation of the bosonic modes. $\\Lambda$ has a representation on the space of Fock states $U(\\Lambda)$. $U$ acts on the computational states as a set of Kraus operators, of which the first one $A:=K_0$ is of importance as it describes the state obtained after postselection on the ancilla qubits.\n",
    "\n",
    "The solution consists on optimizing $\\Lambda$ on the cost function of $1-F$ where $F$ is the fidelity as defined in [Uskov et al.].\n",
    "\n",
    "The presence of the hybrid encoding changes the form of the target $A_t$, while the optimization problem remains the same and can be solved as in the previous problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of the unitary on the Fock states\n",
    "\n",
    "An implementation of the procedure that computes the representation $U$ on the Fock states is given, following [Schee, 2004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import comb, factorial\n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import permutations\n",
    "\n",
    "def factl(l):\n",
    "\treturn [factorial(i) for i in l]\n",
    "\n",
    "def permanent(matrix):\n",
    "    n = len(matrix)\n",
    "    perm_sum = 0\n",
    "\n",
    "    for perm in permutations(range(n)):\n",
    "        product = 1\n",
    "        for i in range(n):\n",
    "            product *= matrix[i, perm[i]]\n",
    "        perm_sum += product\t\n",
    "\n",
    "    return perm_sum\n",
    "\n",
    "def get_A(lam):\n",
    "\tN = lam.shape[0]\n",
    "\tn = 2\n",
    "\tN_out = comb(N+n-1, n)\n",
    "\tA = np.ones((N_out, N_out))*42\n",
    "\n",
    "\tfor idx_n, comb_n in enumerate(combinations_with_replacement(range(N), n)):\n",
    "\t\tfor idx_m, comb_m in enumerate(combinations_with_replacement(range(N), n)):\n",
    "\t\t\tn_i = np.zeros(N, dtype=int)\n",
    "\t\t\tfor x in comb_n:\n",
    "\t\t\t\tn_i[x] += 1\n",
    "\t\t\t\n",
    "\t\t\tm_i = np.zeros(N, dtype=int)\n",
    "\t\t\tfor x in comb_m:\n",
    "\t\t\t\tm_i[x] += 1\n",
    "\n",
    "\t\t\tomega = []\n",
    "\t\t\tfor i,x in enumerate(n_i):\n",
    "\t\t\t\tomega.extend([i]*x)\n",
    "\t\t\tomega = np.array(omega)\n",
    "\n",
    "\t\t\tomegap = []\n",
    "\t\t\tfor i,x in enumerate(m_i):\n",
    "\t\t\t\tomegap.extend([i]*x)\n",
    "\t\t\tomegap = np.array(omegap)\n",
    "\n",
    "\t\t\tsub = lam[omegap]\n",
    "\t\t\tsub = sub[:, omega]\n",
    "\t\t\tprefactor = np.sqrt(np.prod(factl(omega)) * np.prod(factl(omegap)))\n",
    "\t\t\tA[idx_m, idx_n] =  prefactor * permanent(sub)\n",
    "\treturn A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63350251 2.46916383 0.16200673]\n",
      " [8.75533789 4.65245029 7.77731807]\n",
      " [8.61928566 2.32278236 4.34568783]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.02650866e-01, 3.12844298e+00, 2.90286208e-01, 1.21935401e+01,\n",
       "        1.13143072e+00, 1.04984728e-01],\n",
       "       [1.10930571e+01, 2.45657026e+01, 8.97371430e+00, 2.29753240e+01,\n",
       "        2.82237440e+01, 5.03991161e+00],\n",
       "       [1.54441713e+01, 3.21788978e+01, 8.29877295e+00, 1.62219635e+01,\n",
       "        2.22130432e+01, 3.98259902e+00],\n",
       "       [1.53311883e+02, 8.14675486e+01, 1.92596223e+02, 4.32905875e+01,\n",
       "        1.02342635e+02, 2.41946706e+02],\n",
       "       [2.13446569e+02, 8.54715922e+01, 2.10165783e+02, 3.05657639e+01,\n",
       "        7.65662276e+01, 1.91189209e+02],\n",
       "       [2.97168341e+02, 8.00828986e+01, 2.11887233e+02, 2.15812715e+01,\n",
       "        5.71007790e+01, 1.51080022e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example:\n",
    "lam = np.random.random((3,3))*10\n",
    "print(lam)\n",
    "get_A(lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6 # six photonic modes\n",
    "n = 2 # two photons\n",
    "N_fock = comb(N+n-1, n)\n",
    "At = np.identity(N_fock)\n",
    "\n",
    "def index_of_fock_state(N, n, v):\n",
    "\tv = np.array(v)\n",
    "\ti = 0\n",
    "\tfor c in combinations_with_replacement(range(N), n):\n",
    "\t\tfock_s = np.zeros(N, dtype=int)\n",
    "\t\tfor x in c:\n",
    "\t\t\tfock_s[x] += 1\n",
    "\t\tif np.all(np.array(fock_s) == v):\n",
    "\t\t\treturn i\n",
    "\t\ti += 1\n",
    "\n",
    "fock_state = [0,0,1,0,0,1]\n",
    "idx = index_of_fock_state(N, n, fock_state)\n",
    "At[idx, idx] = -1\n",
    "\n",
    "fock_state = [0,0,0,1,0,1]\n",
    "idx = index_of_fock_state(N, n, fock_state)\n",
    "At[idx, idx] = -1\n",
    "\n",
    "# Columns outside of the input space allowed by the encoding can be dropped to obtain a representation in the form of [Uskov et al.]\n",
    "def drop_invalid_input(M):\n",
    "\tallowed_input_space = np.array([\n",
    "\t\t[1,0,0,0,1,0],\n",
    "\t\t[0,1,0,0,1,0],\n",
    "\t\t[0,0,1,0,1,0],\n",
    "\t\t[0,0,0,1,1,0],\n",
    "\t\t[1,0,0,0,0,1],\n",
    "\t\t[0,1,0,0,0,1],\n",
    "\t\t[0,0,1,0,0,1],\n",
    "\t\t[0,0,0,1,0,1]\n",
    "\t])\n",
    "\tallowed_idx = []\n",
    "\tfor state in allowed_input_space:\n",
    "\t\tidx = index_of_fock_state(N, n, state)\n",
    "\t\tallowed_idx.append(idx)\n",
    "\treturn M[:, allowed_idx]\n",
    "\n",
    "At = drop_invalid_input(At)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(At)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization problem\n",
    "\n",
    "The optimization problem is solved as in the first problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def inner_product(A, B, Mc=4):\n",
    "\treturn np.trace(A.conj().T @ B) / 2**Mc\n",
    "\n",
    "def cost_function(Lambda):\n",
    "\treturn 1 - F(Lambda)\n",
    "\n",
    "def cost_function_flattened(flat_Lambda):\n",
    "\tLambda = flat_Lambda.reshape((N, N))\n",
    "\treturn cost_function(Lambda)\n",
    "\n",
    "def F(Lambda):\n",
    "\tA = get_A(Lambda)\n",
    "\treturn inner_product(At, A) * inner_product(A, At) / (inner_product(At, At) * inner_product(A, A))\n",
    "\n",
    "# Define the optimization problem\n",
    "N = 6  # Size of the unitary matrix\n",
    "initial_guess = np.random.random((N,N), dtype=complex).flatten()  # Initial guess for the candidate matrix\n",
    "initial_guess /= np.linalg.norm(initial_guess)\n",
    "# Solve the optimization problem\n",
    "result = minimize(cost_function_flattened, initial_guess, method='BFGS')\n",
    "\n",
    "# Get the optimized candidate matrix\n",
    "optimized_matrix = result.x.reshape((N, N))\n",
    "\n",
    "# Print the optimized candidate matrix\n",
    "print(optimized_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
