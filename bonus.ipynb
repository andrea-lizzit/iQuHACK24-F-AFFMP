{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical estimate of the optimal CZ gate in hybrid encoding in the KLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target operation in the Fock basis is one that brings $|0010>|01>$ into $-|0010>|01>$, $|0001>|01>$ into $-|0001>|01>$ and acts as the identity on the rest. The operator that describes this transformation is the target $A_t$.\n",
    "\n",
    "The problem is framed as an optimization problem on the unitary matrix $\\Lambda$ which determines the transformation of the bosonic modes. $\\Lambda$ has a representation on the space of Fock states $U(\\Lambda)$. $U$ acts on the computational states as a set of Kraus operators, of which the first one $A:=K_0$ is of importance as it describes the state obtained after postselection on the ancilla qubits.\n",
    "\n",
    "The solution consists on optimizing $\\Lambda$ on the cost function of $1-F$ where $F$ is the fidelity as defined in [Uskov et al.].\n",
    "\n",
    "The presence of the hybrid encoding changes the form of the target $A_t$, while the optimization problem remains the same and can be solved as in the previous problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of the unitary on the Fock states\n",
    "\n",
    "An implementation of the procedure that computes the representation $U$ on the Fock states is given, following [Schee, 2004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import comb, factorial\n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import permutations\n",
    "\n",
    "def factl(l):\n",
    "\treturn [factorial(i) for i in l]\n",
    "\n",
    "def permanent(matrix):\n",
    "    n = len(matrix)\n",
    "    perm_sum = 0\n",
    "\n",
    "    for perm in permutations(range(n)):\n",
    "        product = 1\n",
    "        for i in range(n):\n",
    "            product *= matrix[i, perm[i]]\n",
    "        perm_sum += product\t\n",
    "\n",
    "    return perm_sum\n",
    "\n",
    "def get_A(lam):\n",
    "\tN = lam.shape[0]\n",
    "\tn = 2\n",
    "\tN_out = comb(N+n-1, n)\n",
    "\tA = np.ones((N_out, N_out))*42\n",
    "\n",
    "\tfor idx_n, comb_n in enumerate(combinations_with_replacement(range(N), n)):\n",
    "\t\tfor idx_m, comb_m in enumerate(combinations_with_replacement(range(N), n)):\n",
    "\t\t\tn_i = np.zeros(N, dtype=int)\n",
    "\t\t\tfor x in comb_n:\n",
    "\t\t\t\tn_i[x] += 1\n",
    "\t\t\t\n",
    "\t\t\tm_i = np.zeros(N, dtype=int)\n",
    "\t\t\tfor x in comb_m:\n",
    "\t\t\t\tm_i[x] += 1\n",
    "\n",
    "\t\t\tomega = []\n",
    "\t\t\tfor i,x in enumerate(n_i):\n",
    "\t\t\t\tomega.extend([i]*x)\n",
    "\t\t\tomega = np.array(omega)\n",
    "\n",
    "\t\t\tomegap = []\n",
    "\t\t\tfor i,x in enumerate(m_i):\n",
    "\t\t\t\tomegap.extend([i]*x)\n",
    "\t\t\tomegap = np.array(omegap)\n",
    "\n",
    "\t\t\tsub = lam[omegap]\n",
    "\t\t\tsub = sub[:, omega]\n",
    "\t\t\tprefactor = np.sqrt(np.prod(factl(omega)) * np.prod(factl(omegap)))\n",
    "\t\t\tA[idx_m, idx_n] =  prefactor * permanent(sub)\n",
    "\treturn A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.18614442 9.08553164 4.27081625]\n",
      " [1.40547656 8.56390438 1.85138264]\n",
      " [8.88437065 1.30432526 0.27441982]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[168.7704985 , 166.92201143, 110.96580018, 165.09377021,\n",
       "        109.75042871,  72.95948592],\n",
       "       [ 25.82182138,  91.43876417,  32.54048899, 155.6152483 ,\n",
       "         75.51286306,  31.62766023],\n",
       "       [230.83673916, 131.09894188,  80.92874927,  33.51824298,\n",
       "         16.12756694,   6.62981403],\n",
       "       [  3.95072874,  24.0727338 ,   7.35977925, 146.68091639,\n",
       "         44.84489271,  13.71047067],\n",
       "       [ 35.31793234, 110.19283272,  33.66812034,  31.59386146,\n",
       "          9.52982044,   2.87399922],\n",
       "       [315.72816706,  46.35243637,  13.79167861,   6.80505758,\n",
       "          2.02477312,   0.60244989]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example:\n",
    "lam = np.random.random((3,3))*10\n",
    "print(lam)\n",
    "get_A(lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6 # six photonic modes\n",
    "n = 2 # two photons\n",
    "N_fock = comb(N+n-1, n)\n",
    "At = np.identity(N_fock)\n",
    "\n",
    "def index_of_fock_state(N, n, v):\n",
    "\tv = np.array(v)\n",
    "\ti = 0\n",
    "\tfor c in combinations_with_replacement(range(N), n):\n",
    "\t\tfock_s = np.zeros(N, dtype=int)\n",
    "\t\tfor x in c:\n",
    "\t\t\tfock_s[x] += 1\n",
    "\t\tif np.all(np.array(fock_s) == v):\n",
    "\t\t\treturn i\n",
    "\t\ti += 1\n",
    "\n",
    "fock_state = [0,0,1,0,0,1]\n",
    "idx = index_of_fock_state(N, n, fock_state)\n",
    "At[idx, idx] = -1\n",
    "\n",
    "fock_state = [0,0,0,1,0,1]\n",
    "idx = index_of_fock_state(N, n, fock_state)\n",
    "At[idx, idx] = -1\n",
    "\n",
    "# Columns outside of the input space allowed by the encoding can be dropped to obtain a representation in the form of [Uskov et al.]\n",
    "def drop_invalid_input(M):\n",
    "\tallowed_input_space = np.array([\n",
    "\t\t[1,0,0,0,1,0],\n",
    "\t\t[0,1,0,0,1,0],\n",
    "\t\t[0,0,1,0,1,0],\n",
    "\t\t[0,0,0,1,1,0],\n",
    "\t\t[1,0,0,0,0,1],\n",
    "\t\t[0,1,0,0,0,1],\n",
    "\t\t[0,0,1,0,0,1],\n",
    "\t\t[0,0,0,1,0,1]\n",
    "\t])\n",
    "\tallowed_idx = []\n",
    "\tfor state in allowed_input_space:\n",
    "\t\tidx = index_of_fock_state(N, n, state)\n",
    "\t\tallowed_idx.append(idx)\n",
    "\treturn M[:, allowed_idx]\n",
    "\n",
    "At = drop_invalid_input(At)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(At)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization problem\n",
    "\n",
    "The optimization problem is solved as in the first problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def inner_product(A, B, Mc=4):\n",
    "\treturn np.trace(A.conj().T @ B) / 2**Mc\n",
    "\n",
    "def cost_function(Lambda):\n",
    "\treturn 1 - F(Lambda)\n",
    "\n",
    "def cost_function_flattened(flat_Lambda):\n",
    "\tLambda = flat_Lambda.reshape((N, N))\n",
    "\treturn cost_function(Lambda)\n",
    "\n",
    "def F(Lambda):\n",
    "\tA = get_A(Lambda)\n",
    "\treturn inner_product(At, A) * inner_product(A, At) / (inner_product(At, At) * inner_product(A, A))\n",
    "\n",
    "# Define the optimization problem\n",
    "N = 6  # Size of the unitary matrix\n",
    "initial_guess = np.eye(N).flatten()  # Initial guess for the candidate matrix\n",
    "\n",
    "# Solve the optimization problem\n",
    "result = minimize(cost_function_flattened, initial_guess, method='CG')\n",
    "\n",
    "# Get the optimized candidate matrix\n",
    "optimized_matrix = result.x.reshape((N, N))\n",
    "\n",
    "# Print the optimized candidate matrix\n",
    "print(optimized_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
